name: Kubernetes Load Test CI

on:
  pull_request:
    branches: [main]
  workflow_dispatch:

permissions:
  contents: read
  issues: write
  pull-requests: write
  
env:
  KIND_VERSION: "v0.20.0"
  K6_VERSION: "v0.48.0"
  CLUSTER_NAME: "load-test"
  REGISTRY_PORT: "5001"
  NS: "ingress-nginx"
  MON_NS: "monitoring"

jobs:
  load-test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Install Tools
        run: |
          echo "üì¶ Installing dependencies..."
          curl -Lo kind https://kind.sigs.k8s.io/dl/${{ env.KIND_VERSION }}/kind-linux-amd64 && chmod +x kind && sudo mv kind /usr/local/bin/
          curl -s https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash
          curl -Lo k6.tar.gz https://github.com/grafana/k6/releases/download/${{ env.K6_VERSION }}/k6-${{ env.K6_VERSION }}-linux-amd64.tar.gz && tar xzf k6.tar.gz --strip-components 1 && sudo mv k6 /usr/local/bin/
          echo "‚úÖ Tools ready"

      - name: Build & Setup Cluster
        run: |
          echo "üê≥ Building image..."
          docker build -t localhost:${{ env.REGISTRY_PORT }}/http-echo:latest ./application/http-echo
          docker run -d -p ${{ env.REGISTRY_PORT }}:5000 --name kind-registry registry:2
          
          echo "üéØ Creating cluster..."
          cat > kind-config.yaml <<EOF
          kind: Cluster
          apiVersion: kind.x-k8s.io/v1alpha4
          nodes:
            - role: control-plane
              extraPortMappings: [{containerPort: 30080, hostPort: 30080}, {containerPort: 30090, hostPort: 30090}]
            - role: worker
            - role: worker
          containerdConfigPatches:
            - |-
              [plugins."io.containerd.grpc.v1.cri".registry.mirrors."localhost:${{ env.REGISTRY_PORT }}"]
                endpoint = ["http://kind-registry:5000"]
          EOF
          
          kind create cluster --config=kind-config.yaml --name=${{ env.CLUSTER_NAME }}
          docker network connect kind kind-registry
          docker push localhost:${{ env.REGISTRY_PORT }}/http-echo:latest
          kubectl wait --for=condition=ready nodes --all --timeout=300s
          echo "‚úÖ Cluster ready: $(kubectl get nodes --no-headers | wc -l) nodes"

      - name: Deploy Infrastructure & Apps
        run: |
          echo "üèóÔ∏è Deploying..."
          kubectl create ns ${{ env.NS }}
          kubectl apply -f infrastructure_setup/rbac.yaml -f infrastructure_setup/ingress_controller.yaml
          kubectl wait -n ${{ env.NS }} --for=condition=ready pod -l app=ingress-nginx --timeout=300s
          
          helm upgrade --install bar ./application/foo-bar-app -n ${{ env.NS }} --set app.name=bar --set app.responseText=bar --set image.repository=localhost:${{ env.REGISTRY_PORT }}/http-echo --set image.pullPolicy=IfNotPresent --wait
          helm upgrade --install foo ./application/foo-bar-app -n ${{ env.NS }} --set app.name=foo --set app.responseText=foo --set image.repository=localhost:${{ env.REGISTRY_PORT }}/http-echo --set image.pullPolicy=IfNotPresent --wait
          kubectl apply -f infrastructure_setup/ingress.yaml
          echo "‚úÖ Apps deployed"

      - name: Deploy Prometheus
        run: |
          echo "üìä Deploying monitoring..."
          kubectl create ns ${{ env.MON_NS }}
          helm repo add prometheus-community https://prometheus-community.github.io/helm-charts && helm repo update
          helm upgrade --install prometheus prometheus-community/kube-prometheus-stack -n ${{ env.MON_NS }} \
            --set prometheus.service.type=NodePort --set prometheus.service.nodePort=30090 \
            --set grafana.enabled=false --set alertmanager.enabled=false \
            --set prometheusOperator.tls.enabled=false --set prometheus.prometheusSpec.serviceMonitorSelectorNilUsesHelmValues=false --wait --timeout=5m
          kubectl wait -n ${{ env.MON_NS }} --for=condition=ready pod -l app.kubernetes.io/name=prometheus --timeout=300s
          echo "‚úÖ Prometheus ready"

      - name: Health Check & Validate
        run: |
          echo "üè• Validating workloads..."
          for app in ingress-nginx bar foo; do
            kubectl wait -n ${{ env.NS }} --for=condition=ready pod -l app=$app --timeout=300s || exit 1
            echo "‚úÖ $app healthy"
          done
          
          kubectl run test-bar --image=curlimages/curl:latest --rm -i --restart=Never -n ${{ env.NS }} -- curl -sf http://bar.${{ env.NS }}.svc.cluster.local:8080 || exit 1
          kubectl run test-foo --image=curlimages/curl:latest --rm -i --restart=Never -n ${{ env.NS }} -- curl -sf http://foo.${{ env.NS }}.svc.cluster.local:8080 || exit 1
          
          echo "‚úÖ All workloads ready"

      - name: Run Load Test & Capture Metrics
        id: load_test
        run: |
          echo "üìä Waiting for Prometheus baseline..."
          sleep 60
          
          echo "üöÄ Starting load test..."
          set +e
          k6 run testing/load-test.js | tee load-test-results.txt
          [ $? -eq 0 ] && echo "STATUS=‚úÖ PASSED" >> $GITHUB_ENV || echo "STATUS=‚ö†Ô∏è FAILED" >> $GITHUB_ENV
          set -e
          
          echo "‚è≥ Waiting for final metrics..."
          sleep 60
          
          PROM="http://localhost:30090/api/v1/query"
          
          echo "## Resource Utilization During Load Test" > prom-metrics.txt
          echo "" >> prom-metrics.txt
          echo "### Cluster-Wide Metrics" >> prom-metrics.txt
          
          # Cluster CPU %
          CLUSTER_CPU=$(curl -s "${PROM}?query=(1-avg(rate(node_cpu_seconds_total%7Bmode=%22idle%22%7D%5B1m%5D)))*100" | jq -r '.data.result[0].value[1] // "0"')
          CLUSTER_CPU_FMT=$(awk "BEGIN {printf \"%.2f\", $CLUSTER_CPU}")
          echo "- Cluster CPU: ${CLUSTER_CPU_FMT}%" >> prom-metrics.txt
          
          # Cluster Memory %
          CLUSTER_MEM=$(curl -s "${PROM}?query=(1-(sum(node_memory_MemAvailable_bytes)/sum(node_memory_MemTotal_bytes)))*100" | jq -r '.data.result[0].value[1] // "0"')
          CLUSTER_MEM_FMT=$(awk "BEGIN {printf \"%.2f\", $CLUSTER_MEM}")
          echo "- Cluster Memory: ${CLUSTER_MEM_FMT}%" >> prom-metrics.txt
          
          # Total Container Memory
          TOTAL_MEM=$(curl -s "${PROM}?query=sum(container_memory_working_set_bytes%7Bnamespace=%22ingress-nginx%22%7D)/1024/1024" | jq -r '.data.result[0].value[1] // "0"')
          TOTAL_MEM_FMT=$(awk "BEGIN {printf \"%.2f\", $TOTAL_MEM}")
          echo "- Total Container Memory: ${TOTAL_MEM_FMT} MB" >> prom-metrics.txt
          
          # Total Container CPU
          TOTAL_CPU=$(curl -s "${PROM}?query=sum(rate(container_cpu_usage_seconds_total%7Bnamespace=%22ingress-nginx%22%7D%5B1m%5D))*100" | jq -r '.data.result[0].value[1] // "0"')
          TOTAL_CPU_FMT=$(awk "BEGIN {printf \"%.2f\", $TOTAL_CPU}")
          echo "- Total Container CPU: ${TOTAL_CPU_FMT}%" >> prom-metrics.txt
          
          echo "" >> prom-metrics.txt
          echo "### Per-Pod Memory Usage" >> prom-metrics.txt
          curl -s "${PROM}?query=container_memory_working_set_bytes%7Bnamespace=%22ingress-nginx%22%7D" | \
            jq -r '.data.result[] | "- \(.metric.pod): \(((.value[1]|tonumber)/1024/1024)|floor)MB"' >> prom-metrics.txt
          
          echo "" >> prom-metrics.txt
          echo "### Summary" >> prom-metrics.txt
          echo "- Total Pods: $(kubectl get pods -n ingress-nginx --no-headers | wc -l)" >> prom-metrics.txt
          echo "- Test Duration: ~110 seconds" >> prom-metrics.txt
          echo "- Monitoring: Prometheus + cAdvisor + Node Exporter" >> prom-metrics.txt
          
          cat prom-metrics.txt
          echo "‚úÖ Metrics captured successfully"

      - name: Generate Report & Comment PR
        if: always()
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const read = f => { try { return fs.readFileSync(f, 'utf8'); } catch { return 'N/A'; } };
            
            // Extract key k6 metrics
            const k6Results = read('load-test-results.txt');
            const k6Summary = k6Results.split('\n').filter(l => 
              l.includes('‚úì') || l.includes('‚úó') || 
              l.includes('http_req_duration') || 
              l.includes('http_req_failed') || 
              l.includes('http_reqs') ||
              l.includes('checks')
            ).join('\n');
            
            const promMetrics = read('prom-metrics.txt');
            
            const report = `## ${{ env.STATUS || '‚ö†Ô∏è UNKNOWN' }}
            
            **Workflow:** [Run #${{ github.run_number }}](${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }})
            **Commit:** \`${{ github.event.pull_request.head.sha || github.sha }}\`
            **Branch:** \`${{ github.event.pull_request.head.ref || github.ref_name }}\`
            
            ---
            
            ### üìä k6 Load Test Results
            
            <details open>
            <summary><b>Performance Metrics</b></summary>
            
            \`\`\`
            ${k6Summary || 'No k6 results available'}
            \`\`\`
            
            </details>
            
            <details>
            <summary><b>Full k6 Output</b></summary>
            
            \`\`\`
            ${k6Results || 'N/A'}
            \`\`\`
            
            </details>
            
            ---
            
            ### üìà Resource Utilization (Prometheus)
            
            <details>
            <summary><b>Pod & Node Metrics During Load Test</b></summary>
            
            \`\`\`
            ${promMetrics}
            \`\`\`
            
            </details>
            
            ---
            
            ### ‚úÖ Pipeline Summary
            
            | Component | Status |
            |-----------|--------|
            | Multi-node Cluster | ‚úÖ 3 nodes (1 control-plane + 2 workers) |
            | Docker Image Build | ‚úÖ Built from Dockerfile |
            | NGINX Ingress | ‚úÖ Deployed & Healthy |
            | Helm Deployments | ‚úÖ Bar & Foo apps |
            | Health Checks | ‚úÖ All pods ready |
            | Load Testing | ${{ env.STATUS || '‚ö†Ô∏è' }} k6 executed |
            | Monitoring | ‚úÖ Prometheus metrics collected |
            
            ---
            
            ### üéØ Test Configuration
            
            - **Endpoints:** \`bar.localhost:30080\` & \`foo.localhost:30080\`
            - **Load Pattern:** 
              - Ramp-up: 25 users (30s)
              - Sustained: 50 users (1m)
              - Ramp-down: 0 users (20s)
            - **Total Duration:** ~1m 50s
            - **Monitoring:** Prometheus + kube-state-metrics + node-exporter
            
            ---
            
            *ü§ñ Automated by GitHub Actions ‚Ä¢ Built with ‚ù§Ô∏è using KinD, Helm, k6 & Prometheus*
            `;
            
            if (context.issue?.number) {
              github.rest.issues.createComment({
                issue_number: context.issue.number,
                owner: context.repo.owner,
                repo: context.repo.repo,
                body: report
              });
            } else {
              console.log(report);
              console.log('\n‚ö†Ô∏è No PR context - this was triggered via workflow_dispatch');
            }

      - name: Cleanup
        if: always()
        run: |
          kind delete cluster --name ${{ env.CLUSTER_NAME }} 2>/dev/null || true
          docker rm -f kind-registry 2>/dev/null || true
